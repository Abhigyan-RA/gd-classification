{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41304d1",
   "metadata": {},
   "source": [
    "### Notebook to generate DroneRF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da586fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import sum,isrealobj,sqrt\n",
    "from numpy.random import standard_normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spafe.features.lfcc import lfcc\n",
    "import spafe.utils.vis as vis\n",
    "from scipy.signal import get_window\n",
    "import scipy.fftpack as fft\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from loading_functions import *\n",
    "from file_paths import *\n",
    "from feat_gen_functions import *\n",
    "\n",
    "import importlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8705c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feat_gen_functions\n",
    "importlib.reload(feat_gen_functions)\n",
    "from feat_gen_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"DroneRFDistributedProcessing\") \\\n",
    "#     .master(\"local[*]\") \\\n",
    "#     .config(\"spark.driver.memory\", \"8g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"8g\") \\\n",
    "#     .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "#     .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "#     .config(\"spark.default.parallelism\", \"100\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# # Broadcast frequently used constants to all workers\n",
    "# fs = spark.sparkContext.broadcast(40e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c62b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dronerf_raw(main_folder, t_seg):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    from pyspark.sql.functions import udf, lit, col\n",
    "    from pyspark.sql.types import ArrayType, FloatType, IntegerType, StructType, StructField, StringType, LongType\n",
    "\n",
    "    print(f\"Started processing at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    start_time_total = time.time()\n",
    "\n",
    "    # Get file lists\n",
    "    high_freq_files = os.listdir(main_folder+'High/')\n",
    "    low_freq_files = os.listdir(main_folder+'Low/')\n",
    "    \n",
    "    high_freq_files.sort()\n",
    "    low_freq_files.sort()\n",
    "    \n",
    "    print(f\"Found {len(high_freq_files)} high frequency files and {len(low_freq_files)} low frequency files\")\n",
    "    \n",
    "    # Define the segment length\n",
    "    len_seg = int((t_seg/1e3) * 40e6)  # 40 MHz\n",
    "    \n",
    "    # Process files in smaller batches to avoid timeout\n",
    "    batch_size = 5  # Process 5 files at a time\n",
    "    total_batches = (len(high_freq_files) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Arrays to store results\n",
    "    all_features = []\n",
    "    all_y = []\n",
    "    all_y4 = []\n",
    "    all_y10 = []\n",
    "    \n",
    "    # Track processing statistics\n",
    "    timing_stats = []\n",
    "    successful_files = 0\n",
    "    \n",
    "    # Process files in batches\n",
    "    for batch in range(total_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = min((batch + 1) * batch_size, len(high_freq_files))\n",
    "        \n",
    "        print(f\"\\nProcessing batch {batch+1}/{total_batches} (files {start_idx+1}-{end_idx})\")\n",
    "        \n",
    "        # Process each file in the batch\n",
    "        for i in range(start_idx, end_idx):\n",
    "            file_start_time = time.time()\n",
    "            \n",
    "            high_file = high_freq_files[i]\n",
    "            low_file = low_freq_files[i]\n",
    "            \n",
    "            try:\n",
    "                # Get file sizes\n",
    "                high_path = main_folder + 'High/' + high_file\n",
    "                low_path = main_folder + 'Low/' + low_file\n",
    "                file_size_high = os.path.getsize(high_path)\n",
    "                file_size_low = os.path.getsize(low_path)\n",
    "                \n",
    "                print(f\"Processing file {i+1}/{len(high_freq_files)}: {high_file} ({file_size_high/1024:.1f}KB) & {low_file} ({file_size_low/1024:.1f}KB)\")\n",
    "                \n",
    "                # Load RF data\n",
    "                load_start = time.time()\n",
    "                rf_data_h = pd.read_csv(high_path, header=None).values.flatten()\n",
    "                rf_data_l = pd.read_csv(low_path, header=None).values.flatten()\n",
    "                load_time = time.time() - load_start\n",
    "                print(f\"  - Load time: {load_time:.2f}s\")\n",
    "                \n",
    "                if len(rf_data_h) != len(rf_data_l):\n",
    "                    print(f'  - Different lengths: {i}, file name: {low_file}')\n",
    "                    continue\n",
    "                    \n",
    "                if int(high_file[:5]) != int(low_file[:5]):\n",
    "                    print(f\"  - File labels do not match: {high_file} vs {low_file}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Stack features\n",
    "                stack_start = time.time()\n",
    "                rf_sig = np.vstack((rf_data_h, rf_data_l))\n",
    "                stack_time = time.time() - stack_start\n",
    "                \n",
    "                # Calculate segments\n",
    "                n_segs = len(rf_data_h) // len_seg\n",
    "                n_keep = n_segs * len_seg\n",
    "                \n",
    "                if n_segs == 0:\n",
    "                    print(\"  - No segments created (segment length too large)\")\n",
    "                    continue\n",
    "                    \n",
    "                # Split the data\n",
    "                split_start = time.time()\n",
    "                rf_sig_segments = np.split(rf_sig[:, :n_keep], n_segs, axis=1)\n",
    "                split_time = time.time() - split_start\n",
    "                \n",
    "                # Create labels\n",
    "                y_rep = [int(low_file[0])] * n_segs\n",
    "                y4_rep = [int(low_file[:3])] * n_segs\n",
    "                y10_rep = [int(low_file[:5])] * n_segs\n",
    "                \n",
    "                # Add segments to our result arrays\n",
    "                all_features.extend(rf_sig_segments)\n",
    "                all_y.extend(y_rep)\n",
    "                all_y4.extend(y4_rep)\n",
    "                all_y10.extend(y10_rep)\n",
    "                \n",
    "                successful_files += 1\n",
    "                \n",
    "                file_time = time.time() - file_start_time\n",
    "                print(f\"  - Processed {n_segs} segments: Stack time: {stack_time:.2f}s, \"\n",
    "                      f\"Split time: {split_time:.2f}s, Total time: {file_time:.2f}s\")\n",
    "                \n",
    "                # Store timing stats\n",
    "                timing_stats.append({\n",
    "                    \"high_file\": high_file,\n",
    "                    \"low_file\": low_file,\n",
    "                    \"processing_time\": int(file_time * 1000),\n",
    "                    \"file_size_high\": file_size_high,\n",
    "                    \"file_size_low\": file_size_low,\n",
    "                    \"is_valid\": 1\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                file_time = time.time() - file_start_time\n",
    "                print(f\"  - Error processing file pair {i}: {e} - Time: {file_time:.2f}s\")\n",
    "                \n",
    "                # Try to get file sizes if possible\n",
    "                try:\n",
    "                    file_size_high = os.path.getsize(main_folder + 'High/' + high_file)\n",
    "                    file_size_low = os.path.getsize(main_folder + 'Low/' + low_file)\n",
    "                except:\n",
    "                    file_size_high = 0\n",
    "                    file_size_low = 0\n",
    "                    \n",
    "                timing_stats.append({\n",
    "                    \"high_file\": high_file,\n",
    "                    \"low_file\": low_file,\n",
    "                    \"processing_time\": int(file_time * 1000),\n",
    "                    \"file_size_high\": file_size_high,\n",
    "                    \"file_size_low\": file_size_low,\n",
    "                    \"is_valid\": 0\n",
    "                })\n",
    "    \n",
    "    # Process timing stats\n",
    "    print(f\"\\nProcessing time summary:\")\n",
    "    total_valid = successful_files\n",
    "    total_files = len(high_freq_files)\n",
    "    \n",
    "    print(f\"Successfully processed {total_valid}/{total_files} file pairs\")\n",
    "    \n",
    "    # Sort by processing time to show slowest files\n",
    "    timing_stats.sort(key=lambda x: x[\"processing_time\"], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop 5 slowest files:\")\n",
    "    for i in range(min(5, len(timing_stats))):\n",
    "        row = timing_stats[i]\n",
    "        print(f\"  {row['high_file']} & {row['low_file']}: {row['processing_time']/1000:.2f}s \"\n",
    "              f\"({row['file_size_high']/1024:.1f}KB, {row['file_size_low']/1024:.1f}KB)\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    print(f\"\\nConverting to numpy arrays...\")\n",
    "    convert_start = time.time()\n",
    "    \n",
    "    Xs_arr = np.array(all_features)\n",
    "    ys_arr = np.array(all_y)\n",
    "    y4s_arr = np.array(all_y4)\n",
    "    y10s_arr = np.array(all_y10)\n",
    "    \n",
    "    convert_time = time.time() - convert_start\n",
    "    print(f\"Array conversion completed in {convert_time:.2f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time_total\n",
    "    print(f\"\\nTotal processing time: {total_time:.2f}s\")\n",
    "    print(f\"Final arrays - Xs: {Xs_arr.shape}, ys: {ys_arr.shape}, y4s: {y4s_arr.shape}, y10s: {y10s_arr.shape}\")\n",
    "    \n",
    "    return Xs_arr, ys_arr, y4s_arr, y10s_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a573bd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing at 16:19:42\n",
      "Found 2 high frequency files and 2 low frequency files\n",
      "\n",
      "Processing batch 1/1 (files 1-2)\n",
      "Processing file 1/2: 10011H_0.csv (92069.7KB) & 10011L_0.csv (94588.4KB)\n",
      "  - Load time: 392.39s\n",
      "  - Processed 12 segments: Stack time: 0.05s, Split time: 0.00s, Total time: 392.45s\n",
      "Processing file 2/2: 11000H_0.csv (93690.4KB) & 11000L_0.csv (97027.5KB)\n",
      "  - Load time: 376.50s\n",
      "  - Processed 12 segments: Stack time: 0.05s, Split time: 0.00s, Total time: 376.54s\n",
      "\n",
      "Processing time summary:\n",
      "Successfully processed 2/2 file pairs\n",
      "\n",
      "Top 5 slowest files:\n",
      "  10011H_0.csv & 10011L_0.csv: 392.45s (92069.7KB, 94588.4KB)\n",
      "  11000H_0.csv & 11000L_0.csv: 376.54s (93690.4KB, 97027.5KB)\n",
      "\n",
      "Converting to numpy arrays...\n",
      "Array conversion completed in 0.08s\n",
      "\n",
      "Total processing time: 769.07s\n",
      "Final arrays - Xs: (24, 2, 800000), ys: (24,), y4s: (24,), y10s: (24,)\n",
      "length of X: 24 length of y: 24\n"
     ]
    }
   ],
   "source": [
    "# Dataset Info\n",
    "main_folder = './Data/DroneRF/'\n",
    "t_seg = 20\n",
    "Xs_arr, ys_arr, y4s_arr, y10s_arr = load_dronerf_raw(main_folder, t_seg)\n",
    "fs = 40e6 #40 MHz\n",
    "\n",
    "print('length of X:', len(Xs_arr), 'length of y:', len(ys_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4cde691",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_seg = 1024 # length of each segment (powers of 2)\n",
    "n_overlap_spec = 120\n",
    "win_type = 'hamming' # make ends of each segment match\n",
    "high_low = 'H' #'L', 'H' # high or low range of frequency\n",
    "feature_to_save = ['PSD'] # what features to generate and save: SPEC or PSD\n",
    "format_to_save = ['ARR'] # IMG or ARR or RAW\n",
    "to_add = True\n",
    "spec_han_window = np.hanning(n_per_seg)\n",
    "\n",
    "# Image properties\n",
    "dim_px = (224, 224) # dimension of image pixels\n",
    "dpi = 100\n",
    "\n",
    "# Raw input len\n",
    "v_samp_len = 10000\n",
    "\n",
    "# data saving folders\n",
    "features_folder = dronerf_feat_path\n",
    "date_string = date.today()\n",
    "# folder naming: ARR_FEAT_NFFT_SAMPLELENGTH\n",
    "arr_spec_folder = \"ARR_SPEC_\"+high_low+'_'+str(n_per_seg)+\"_\"+str(t_seg)+\"/\"\n",
    "arr_psd_folder = \"ARR_PSD_\"+high_low+'_'+str(n_per_seg)+\"_\"+str(t_seg)+\"/\"\n",
    "img_spec_folder = \"IMG_SPEC_\"+high_low+'_'+str(n_per_seg)+\"_\"+str(t_seg)+\"/\"\n",
    "img_psd_folder = \"IMG_PSD_\"+high_low+'_'+str(n_per_seg)+\"_\"+str(t_seg)+\"/\"\n",
    "raw_folder = 'RAW_VOLT_'+str(v_samp_len)+\"_\"+str(t_seg)+\"/\" # high and low frequency stacked together\n",
    "\n",
    "existing_folders = os.listdir(features_folder)\n",
    "\n",
    "if high_low == 'H':\n",
    "    i_hl = 0\n",
    "elif high_low == 'L':\n",
    "    i_hl = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5abd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PSD in ARRAY format\n"
     ]
    }
   ],
   "source": [
    "# check if this set of parameters already exists\n",
    "# check if each of the 4 folders exist\n",
    "sa_save = False   #spec array\n",
    "si_save = False   #spec imag\n",
    "pa_save = False   #psd array\n",
    "pi_save = False   #psd imag\n",
    "raw_save = False # raw high low signals\n",
    "\n",
    "if 'SPEC' in feature_to_save:\n",
    "    if 'ARR' in format_to_save:\n",
    "        if arr_spec_folder not in existing_folders or to_add:\n",
    "            try:\n",
    "                os.mkdir(features_folder+arr_spec_folder)\n",
    "            except:\n",
    "                print('folder already exist - adding')\n",
    "            sa_save = True\n",
    "            print('Generating SPEC in ARRAY format')\n",
    "        else:\n",
    "            print('Spec Arr folder already exists')\n",
    "    if 'IMG' in format_to_save:\n",
    "        if img_spec_folder not in existing_folders or to_add:\n",
    "            try:\n",
    "                os.mkdir(features_folder+img_spec_folder)\n",
    "            except:\n",
    "                print('folder already exist - adding')\n",
    "            si_save = True\n",
    "            print('Generating SPEC in IMAGE format')\n",
    "        else:\n",
    "            print('Spec Arr folder already exists')\n",
    "if 'PSD' in feature_to_save:\n",
    "    if 'ARR' in format_to_save:\n",
    "        if arr_psd_folder not in existing_folders or to_add:\n",
    "            try:\n",
    "                os.mkdir(features_folder+arr_psd_folder)\n",
    "            except:\n",
    "                print('folder already exist - adding')\n",
    "            pa_save = True\n",
    "            print('Generating PSD in ARRAY format')\n",
    "        else:\n",
    "            print('PSD Arr folder already exists')\n",
    "    if 'IMG' in format_to_save:\n",
    "        if img_psd_folder not in existing_folders or to_add:\n",
    "            try:\n",
    "                os.mkdir(features_folder+img_psd_folder)\n",
    "            except:\n",
    "                print('folder already exist - adding')\n",
    "            pi_save = True\n",
    "            print('Generating PSD in IMAGE format')\n",
    "        else:\n",
    "            print('PSD Arr folder already exists')\n",
    "\n",
    "if 'RAW' in feature_to_save:\n",
    "    if raw_folder in existing_folders or to_add:\n",
    "        try:\n",
    "            os.mkdir(features_folder+raw_folder)\n",
    "        except:\n",
    "            print('RAW V folder already exists')\n",
    "        raw_save = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd991c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features_DroneRF/ARR_PSD_H_1024_20/PSD_1024_23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if all([not sa_save, not si_save, not pa_save, not pi_save, not raw_save]):\n",
    "    print('Features Already Exist - Do Not Generate')\n",
    "else:\n",
    "    n_parts = 24 # process the data in 10 parts so memory doesn't overwhelm\n",
    "\n",
    "    indices_ranges = np.split(np.array(range(len(Xs_arr))), n_parts) \n",
    "    for i in range(n_parts):\n",
    "        BILABEL = []\n",
    "        DRONELABEL = []\n",
    "        MODELALBEL = []\n",
    "        F_PSD = []\n",
    "        F_SPEC = []\n",
    "        F_V = []\n",
    "        ir = indices_ranges[i]\n",
    "        for j in tqdm(range(len(ir))):\n",
    "            d_real = Xs_arr[ir[j]][i_hl]\n",
    "            \n",
    "            # if save raw data\n",
    "            if raw_save:\n",
    "                t = np.arange(0, len(d_real))\n",
    "                f_high = interpolate.interp1d(t, Xs_arr[ir[j]][0])\n",
    "                f_low = interpolate.interp1d(t, Xs_arr[ir[j]][1])\n",
    "                tt = np.linspace(0, len(d_real)-1, num=v_samp_len)\n",
    "\n",
    "                d_v = np.stack((f_high(tt), f_low(tt)), axis=0)\n",
    "                F_V.append(d_v)\n",
    "            \n",
    "            if pa_save or pi_save:\n",
    "            # calculate PSD\n",
    "                fpsd, Pxx_den = signal.welch(d_real, fs, window=win_type, nperseg=n_per_seg)\n",
    "                if pa_save:\n",
    "                    F_PSD.append(Pxx_den)\n",
    "                if pi_save:\n",
    "                    save_psd_image_rf(features_folder, img_psd_folder,\n",
    "                                      y10s_arr[ir[j]], i, j, Pxx_den, dim_px, dpi)\n",
    "            \n",
    "            if sa_save or si_save:\n",
    "            # calculate spectrogram\n",
    "            # welch's method older\n",
    "#           fspec, t, Sxx = signal.spectrogram(d_real, fs, window=win_type, nperseg=n_per_seg)\n",
    "            \n",
    "                if si_save: # set up fig properties if saving images\n",
    "                    plt.clf()\n",
    "                    fig,ax = plt.subplots(1, figsize=(dim_px[0]/dpi, dim_px[1]/dpi), dpi=dpi)\n",
    "                    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "                    ax.axis('tight')\n",
    "                    ax.axis('off')\n",
    "\n",
    "                spec, _, _, _ = plt.specgram(d_real, NFFT=n_per_seg, Fs=fs, window=spec_han_window, \n",
    "                                  noverlap=n_overlap_spec, sides='onesided')\n",
    "                if si_save:\n",
    "                    save_spec_image_fig_rf(features_folder, img_spec_folder, \n",
    "                                           y10s_arr[ir[j]], i, j, fig, dpi)\n",
    "                if sa_save:\n",
    "                    F_SPEC.append(interpolate_2d(Sxx, (224,224)))\n",
    "\n",
    "            # Labels\n",
    "            BILABEL.append(ys_arr[ir[j]])\n",
    "            DRONELABEL.append(y4s_arr[ir[j]])\n",
    "            MODELALBEL.append(y10s_arr[ir[j]])\n",
    "        \n",
    "        if sa_save:\n",
    "            save_array_rf(features_folder+arr_spec_folder, F_SPEC, BILABEL, DRONELABEL, MODELALBEL, 'SPEC', n_per_seg, i)\n",
    "        if pa_save:\n",
    "            save_array_rf(features_folder+arr_psd_folder, F_PSD, BILABEL, DRONELABEL, MODELALBEL, 'PSD', n_per_seg, i)\n",
    "        if raw_save:\n",
    "            save_array_rf(features_folder+raw_folder, F_V, BILABEL, DRONELABEL, MODELALBEL, 'RAW', '', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data\\\\DroneRF\\\\High\\\\10011H_0.csv')  # `.compute()` converts to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba996a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDroneRF\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mHigh\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43m10011H_0.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\utils.py:613\u001b[39m, in \u001b[36mexpanduser_path_arg.<locals>.decorator.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patharg, Path):\n\u001b[32m    612\u001b[39m         params.arguments[argname] = patharg.expanduser()\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:144\u001b[39m, in \u001b[36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m \u001b[33;03mAny\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m LogMode.get() == \u001b[33m\"\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m logger = get_logger()\n\u001b[32m    147\u001b[39m logger.log(log_level, start_line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\pandas\\io.py:226\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    224\u001b[39m _, _, _, f_locals = inspect.getargvalues(inspect.currentframe())\n\u001b[32m    225\u001b[39m kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m f_locals.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _pd_read_csv_signature}\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\pandas\\io.py:116\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecution\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdispatching\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfactories\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdispatcher\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FactoryDispatcher\n\u001b[32m    115\u001b[39m squeeze = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33msqueeze\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m pd_obj = \u001b[43mFactoryDispatcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# This happens when `read_csv` returns a TextFileReader object for iterating through\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pd_obj, TextFileReader):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\dispatcher.py:207\u001b[39m, in \u001b[36mFactoryDispatcher.read_csv\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;129m@_inherit_docstrings\u001b[39m(factories.BaseFactory._read_csv)\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_csv\u001b[39m(\u001b[38;5;28mcls\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m._read_csv(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\dispatcher.py:115\u001b[39m, in \u001b[36mFactoryDispatcher.get_factory\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _update_engine\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_update_engine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     Engine.subscribe(\u001b[38;5;28mcls\u001b[39m._update_factory)\n\u001b[32m    117\u001b[39m     StorageFormat.subscribe(\u001b[38;5;28mcls\u001b[39m._update_factory)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\config\\pubsub.py:295\u001b[39m, in \u001b[36mParameter.subscribe\u001b[39m\u001b[34m(cls, callback)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[33;03mAdd `callback` to the `_subs` list and then execute it.\u001b[39;00m\n\u001b[32m    288\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    292\u001b[39m \u001b[33;03m    Callable to execute.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[38;5;28mcls\u001b[39m._subs.append(callback)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\pandas\\__init__.py:121\u001b[39m, in \u001b[36m_update_engine\u001b[39m\u001b[34m(publisher)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m publisher.get() == \u001b[33m\"\u001b[39m\u001b[33mRay\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_first_update.get(\u001b[33m\"\u001b[39m\u001b[33mRay\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecution\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mray\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_ray\n\u001b[32m    123\u001b[39m         initialize_ray()\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m publisher.get() == \u001b[33m\"\u001b[39m\u001b[33mDask\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\core\\execution\\ray\\common\\__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Licensed to Modin Development Team under one or more contributor license agreements.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# See the NOTICE file distributed with this work for additional information regarding\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# copyright ownership.  The Modin Development Team licenses this file to you under the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ANY KIND, either express or implied. See the License for the specific language\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# governing permissions and limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"Common utilities for Ray execution engine.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaterializationHook, RayWrapper, SignalActor\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_ray\n\u001b[32m     19\u001b[39m __all__ = [\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minitialize_ray\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRayWrapper\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMaterializationHook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSignalActor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\GD-drone\\gddrone\\Lib\\site-packages\\modin\\core\\execution\\ray\\common\\engine_wrapper.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequence\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mray\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RayTaskCustomResources\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merror_message\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ErrorMessage\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gddrone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
