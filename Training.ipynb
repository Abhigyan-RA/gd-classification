{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.signal import convolve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_filter(signal, window_size=5):\n",
    "    \"\"\"\n",
    "    Applies a moving average filter (FIR filter with uniform weights)\n",
    "    to smooth the input signal.\n",
    "    \"\"\"\n",
    "    return np.convolve(signal, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "def extract_features(signal):\n",
    "    \"\"\"\n",
    "    Extracts simple statistical features from the signal:\n",
    "    mean, standard deviation, maximum, minimum, and energy.\n",
    "    \"\"\"\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    maximum = np.max(signal)\n",
    "    minimum = np.min(signal)\n",
    "    energy = np.sum(signal**2)\n",
    "    return np.array([mean, std, maximum, minimum, energy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segment_files(folder_path):\n",
    "    \"\"\"\n",
    "    Groups CSV files in the given folder into segments by pairing the low band (L) \n",
    "    and high band (H) parts. \n",
    "    File naming convention: <segmentID><L/H>_<pairIndex>.csv\n",
    "    e.g., \"11000L_1.csv\" is the low band and \"11000H_1.csv\" is the high band.\n",
    "    The function loads both parts and concatenates them to form a complete segment.\n",
    "    \"\"\"\n",
    "    segment_dict = {}\n",
    "    # Regular expression to parse filenames (L for low band, H for high band)\n",
    "    pattern = re.compile(r\"(\\d+)([LH])_(\\d+)\\.csv\")\n",
    "    # List all CSV files in the folder\n",
    "    files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    for file in files:\n",
    "        basename = os.path.basename(file)\n",
    "        match = pattern.match(basename)\n",
    "        if match:\n",
    "            seg_id = match.group(1)   # e.g., \"11000\"\n",
    "            band = match.group(2)     # \"L\" (low band) or \"H\" (high band)\n",
    "            pair_idx = match.group(3) # e.g., \"1\"\n",
    "            key = (seg_id, pair_idx)\n",
    "            if key not in segment_dict:\n",
    "                segment_dict[key] = {}\n",
    "            segment_dict[key][band] = file\n",
    "        else:\n",
    "            print(f\"Filename {basename} did not match expected pattern and will be skipped.\")\n",
    "    \n",
    "    segments = []\n",
    "    for key, parts in segment_dict.items():\n",
    "        if 'L' in parts and 'H' in parts:\n",
    "            try:\n",
    "                # Load both low band and high band parts; adjust delimiter if needed\n",
    "                data_low = np.loadtxt(parts['L'], delimiter=',')\n",
    "                data_high = np.loadtxt(parts['H'], delimiter=',')\n",
    "                # Combine the two parts by concatenation along the time axis\n",
    "                segment = np.concatenate((data_low, data_high))\n",
    "                segments.append(segment)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading segment {key}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping segment {key} because it doesn't have both low (L) and high (H) band parts.\")\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './Data/DroneRF'  # e.g., \"/data/DroneRF\"\n",
    "drone_folders = [\n",
    "  'Data\\DroneRF\\AR drone',\n",
    "    'Data\\DroneRF\\Bepop drone',\n",
    "    'Data\\DroneRF\\Phantom drone'\n",
    "]\n",
    "background_folder = os.path.join(base_dir, 'Background RF activities')\n",
    "\n",
    "# ----- Load the Data -----\n",
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segments from Data\\DroneRF\\AR drone\n",
      "Loading segments from Data\\DroneRF\\Bepop drone\n",
      "Error loading segment ('10000', '15'): \n",
      "Error loading segment ('10000', '16'): \n",
      "Error loading segment ('10000', '17'): \n",
      "Error loading segment ('10000', '18'): \n",
      "Error loading segment ('10000', '19'): \n",
      "Error loading segment ('10000', '20'): \n",
      "Error loading segment ('10000', '3'): \n",
      "Error loading segment ('10000', '4'): \n",
      "Error loading segment ('10000', '5'): \n",
      "Error loading segment ('10000', '6'): \n",
      "Error loading segment ('10000', '7'): \n",
      "Error loading segment ('10000', '8'): \n",
      "Error loading segment ('10000', '9'): \n",
      "Error loading segment ('10001', '0'): \n",
      "Error loading segment ('10001', '1'): \n",
      "Error loading segment ('10001', '10'): \n",
      "Error loading segment ('10001', '11'): \n",
      "Error loading segment ('10001', '12'): \n",
      "Error loading segment ('10001', '13'): \n",
      "Error loading segment ('10001', '14'): \n",
      "Error loading segment ('10001', '15'): \n",
      "Error loading segment ('10001', '16'): \n",
      "Error loading segment ('10001', '17'): \n",
      "Error loading segment ('10001', '18'): \n",
      "Error loading segment ('10001', '19'): \n",
      "Error loading segment ('10001', '2'): \n",
      "Error loading segment ('10001', '20'): \n",
      "Error loading segment ('10001', '3'): \n",
      "Error loading segment ('10001', '4'): \n",
      "Error loading segment ('10001', '5'): \n",
      "Error loading segment ('10001', '6'): \n",
      "Error loading segment ('10001', '7'): \n",
      "Error loading segment ('10001', '8'): \n",
      "Error loading segment ('10001', '9'): \n",
      "Error loading segment ('10010', '0'): \n",
      "Error loading segment ('10010', '1'): \n",
      "Error loading segment ('10010', '10'): \n",
      "Error loading segment ('10010', '11'): \n",
      "Error loading segment ('10010', '12'): \n",
      "Error loading segment ('10010', '13'): \n",
      "Error loading segment ('10010', '14'): \n",
      "Error loading segment ('10010', '15'): \n",
      "Error loading segment ('10010', '16'): \n",
      "Error loading segment ('10010', '17'): \n",
      "Error loading segment ('10010', '18'): \n",
      "Error loading segment ('10010', '19'): \n",
      "Error loading segment ('10010', '2'): \n",
      "Error loading segment ('10010', '20'): \n",
      "Error loading segment ('10010', '3'): \n",
      "Error loading segment ('10010', '4'): \n",
      "Error loading segment ('10010', '5'): \n",
      "Error loading segment ('10010', '6'): \n",
      "Error loading segment ('10010', '7'): \n",
      "Error loading segment ('10010', '8'): \n",
      "Error loading segment ('10010', '9'): \n",
      "Error loading segment ('10011', '0'): \n",
      "Error loading segment ('10011', '1'): \n",
      "Error loading segment ('10011', '10'): \n",
      "Error loading segment ('10011', '11'): \n",
      "Error loading segment ('10011', '12'): \n",
      "Error loading segment ('10011', '13'): \n",
      "Error loading segment ('10011', '14'): \n",
      "Error loading segment ('10011', '15'): \n",
      "Error loading segment ('10011', '16'): \n",
      "Error loading segment ('10011', '18'): \n",
      "Error loading segment ('10011', '3'): \n",
      "Error loading segment ('10011', '4'): \n",
      "Error loading segment ('10011', '5'): \n",
      "Error loading segment ('10011', '6'): \n",
      "Error loading segment ('10011', '7'): \n",
      "Error loading segment ('10011', '8'): \n",
      "Error loading segment ('10011', '9'): \n",
      "Loading segments from Data\\DroneRF\\Phantom drone\n"
     ]
    }
   ],
   "source": [
    "# Load and process drone segments (label 1 for drone present)\n",
    "for folder in drone_folders:\n",
    "    print(f\"Loading segments from {folder}\")\n",
    "    segments = load_segment_files(folder)\n",
    "    for segment in segments:\n",
    "        # Apply moving average filter for smoothing\n",
    "        filtered_signal = moving_average_filter(segment, window_size=5)\n",
    "        # Normalize signal between -1 and 1\n",
    "        if np.max(filtered_signal) != np.min(filtered_signal):\n",
    "            norm_signal = 2 * (filtered_signal - np.min(filtered_signal)) / (np.max(filtered_signal) - np.min(filtered_signal)) - 1\n",
    "        else:\n",
    "            norm_signal = filtered_signal\n",
    "        features = extract_features(norm_signal)\n",
    "        X.append(features)\n",
    "        y.append(1)\n",
    "\n",
    "# Load and process background segments (label 0 for no drone present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segments from ./Data/DroneRF\\Background RF activities\n"
     ]
    }
   ],
   "source": [
    "r=[]\n",
    "z=[]\n",
    "print(f\"Loading segments from {background_folder}\")\n",
    "background_segments = load_segment_files('Data\\DroneRF\\Background RF activites')\n",
    "for segment in background_segments:\n",
    "    filtered_signal = moving_average_filter(segment, window_size=5)\n",
    "    if np.max(filtered_signal) != np.min(filtered_signal):\n",
    "        norm_signal = 2 * (filtered_signal - np.min(filtered_signal)) / (np.max(filtered_signal) - np.min(filtered_signal)) - 1\n",
    "    else:\n",
    "        norm_signal = filtered_signal\n",
    "    features = extract_features(norm_signal)\n",
    "    r.append(features)\n",
    "    z.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.array(r)\n",
    "z2 = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.21589955e-03,  2.00634776e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.82360906e+03],\n",
       "       [-2.57873564e-02,  1.63705201e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.86596299e+04],\n",
       "       [ 3.64317034e-02,  1.82772561e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.32265355e+04],\n",
       "       [ 4.65926416e-02,  1.80271012e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.99170026e+04],\n",
       "       [-1.36457697e-02,  2.49172729e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.61415472e+04],\n",
       "       [-3.33332684e-02,  1.78745033e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.86120872e+04],\n",
       "       [ 7.02934059e-02,  1.80938459e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.05370982e+05],\n",
       "       [-1.39480955e-02,  1.87423963e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.09165336e+04],\n",
       "       [ 1.56227354e-02,  1.84402909e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.16822814e+04],\n",
       "       [ 5.12768178e-02,  2.22877750e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  6.25211268e+04],\n",
       "       [ 1.98110016e-02,  1.94021370e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.53783710e+04],\n",
       "       [ 8.12152029e-03,  2.02929556e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.55526089e+03],\n",
       "       [-3.66610955e-03,  2.60423671e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.38329021e+04],\n",
       "       [ 1.62512869e-02,  1.86261688e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.22207673e+04],\n",
       "       [ 2.26814357e-02,  2.73730829e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.52746588e+04],\n",
       "       [-1.67076034e-02,  2.82101716e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.14991516e+04],\n",
       "       [ 4.32566779e-02,  3.99520098e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  6.93460516e+04],\n",
       "       [-9.83041395e-03,  1.75692512e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.10631094e+03],\n",
       "       [ 5.03116438e-02,  1.57871502e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.56099010e+04],\n",
       "       [-2.52275114e-02,  2.46412204e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.48723365e+04],\n",
       "       [-2.26608396e-02,  1.99597701e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.82381179e+04],\n",
       "       [ 1.56084663e-02,  2.19724116e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.45282190e+04],\n",
       "       [ 5.94037505e-02,  1.50166785e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  7.50861092e+04],\n",
       "       [ 3.97667552e-02,  3.18219380e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.18806007e+04],\n",
       "       [ 1.04821860e-03,  4.04249626e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.27055207e+04],\n",
       "       [-6.81073403e-02,  2.63182953e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.06625228e+05],\n",
       "       [-3.07667474e-03,  2.86090835e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.65589084e+04],\n",
       "       [-1.58028338e-02,  3.07125061e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.38597470e+04],\n",
       "       [-2.30843009e-02,  3.53973125e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.57170865e+04],\n",
       "       [ 7.36872349e-02,  2.01605953e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.16725140e+05],\n",
       "       [-2.60686651e-02,  4.06408215e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.66250242e+04],\n",
       "       [ 3.35859297e-03,  2.19394622e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.85240101e+03],\n",
       "       [ 9.53723457e-03,  1.86555310e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.77975186e+03],\n",
       "       [-1.81006357e-02,  1.31207431e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.99573622e+03],\n",
       "       [ 2.44971844e-02,  2.61297939e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.56575583e+04],\n",
       "       [-1.77643696e-02,  2.29765619e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.68699011e+04],\n",
       "       [-6.39586192e-03,  1.78673674e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  7.20299590e+03],\n",
       "       [-1.25809431e-02,  1.59242397e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.23722916e+03],\n",
       "       [-3.07319473e-02,  2.08125510e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.75522918e+04],\n",
       "       [ 5.11669017e-02,  1.70021694e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.81425003e+04],\n",
       "       [-8.15395385e-03,  2.93595051e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.85693463e+04],\n",
       "       [-7.31976381e-02,  2.19673347e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.16809137e+05],\n",
       "       [-2.95009962e-02,  3.18332775e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.76733191e+04],\n",
       "       [-1.65777390e-02,  4.70909124e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.98474992e+04],\n",
       "       [-8.96287746e-03,  2.76175292e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.68612184e+04],\n",
       "       [ 1.45125364e-02,  3.57369487e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.97548583e+04],\n",
       "       [-2.12983281e-02,  2.79020254e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.46428311e+04],\n",
       "       [-7.32988310e-04,  2.67141355e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.42836433e+04],\n",
       "       [ 3.12407915e-02,  3.59763787e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.54057285e+04],\n",
       "       [ 1.32672044e-02,  3.93551702e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.44969558e+04],\n",
       "       [ 1.64423361e-02,  4.59870930e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.77032532e+04],\n",
       "       [-6.95093654e-03,  3.58022782e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.66023676e+04],\n",
       "       [-7.96966059e-03,  2.94720158e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.86423004e+04],\n",
       "       [ 5.11481266e-03,  3.23449084e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.14470839e+04],\n",
       "       [ 2.31761587e-02,  3.87425858e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.07624375e+04],\n",
       "       [-4.93609071e-03,  3.52556325e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.53464872e+04],\n",
       "       [-2.38647284e-03,  2.37717026e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.14157797e+04],\n",
       "       [-9.32452275e-03,  3.67576907e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.87614852e+04],\n",
       "       [ 2.63341377e-02,  2.68013237e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.82359496e+04],\n",
       "       [ 5.84593183e-02,  4.20149941e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.03655012e+05],\n",
       "       [ 2.79471628e-02,  3.63987750e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.21182861e+04],\n",
       "       [-2.50863973e-02,  3.36748853e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.52664975e+04],\n",
       "       [-5.73113856e-02,  3.68934237e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.29143742e+04],\n",
       "       [ 1.69121124e-03,  3.27032073e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.14471950e+04],\n",
       "       [ 2.34787673e-02,  5.28075217e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  6.67977238e+04],\n",
       "       [-6.49824383e-04,  3.72935391e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  2.78246011e+04],\n",
       "       [-1.64439181e-03,  4.88266955e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.77349948e+04],\n",
       "       [-2.07413518e-02,  4.77757440e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.42544970e+04],\n",
       "       [-4.79492692e-02,  4.68221515e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.98289077e+04],\n",
       "       [-3.73815053e-05,  4.94158079e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.88384595e+04],\n",
       "       [ 3.14899131e-02,  2.89034589e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.65404840e+04],\n",
       "       [ 1.46912732e-02,  3.99906668e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.63017314e+04],\n",
       "       [-4.91964479e-02,  3.93360563e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  7.93523004e+04],\n",
       "       [ 9.16004735e-03,  8.25329798e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.37911957e+05],\n",
       "       [ 4.09934390e-02,  8.66572381e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.83798742e+05],\n",
       "       [-1.23239437e-02,  1.25952749e-01,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.20319429e+05],\n",
       "       [-3.28279755e-02,  8.04361762e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.50953058e+05],\n",
       "       [-6.64032149e-02,  4.71970880e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.32739015e+05],\n",
       "       [-5.83025568e-02,  4.06127285e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.00971617e+05],\n",
       "       [-2.49512408e-02,  4.80717635e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.86691656e+04],\n",
       "       [ 7.65783511e-03,  3.94158751e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.22450665e+04],\n",
       "       [-1.95334344e-02,  4.29451994e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.45168954e+04],\n",
       "       [ 6.04507820e-02,  4.05915813e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.06039449e+05],\n",
       "       [-1.78986312e-02,  3.64176685e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.29321450e+04],\n",
       "       [ 3.81191829e-02,  3.23997605e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.00563216e+04],\n",
       "       [ 4.04714133e-02,  4.80683581e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  7.89700310e+04],\n",
       "       [ 1.97075824e-02,  3.67005067e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.47063130e+04],\n",
       "       [ 2.65732412e-02,  3.45399866e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.79829488e+04],\n",
       "       [-3.33752386e-02,  4.30704014e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.93793087e+04],\n",
       "       [-7.81259501e-02,  3.65998003e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.48864160e+05],\n",
       "       [ 2.62738849e-02,  3.13809726e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.35016426e+04],\n",
       "       [-5.38593207e-02,  3.67148418e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.49761037e+04],\n",
       "       [ 1.23584493e-02,  4.04059202e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.57073861e+04],\n",
       "       [ 3.04978109e-02,  4.89077528e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  6.64416817e+04],\n",
       "       [ 1.90063873e-02,  4.61688664e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.98561297e+04],\n",
       "       [-4.53412581e-02,  4.90360860e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  8.92073306e+04],\n",
       "       [ 8.25811576e-03,  5.09280406e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.32372253e+04],\n",
       "       [ 5.55678675e-04,  4.11938576e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.39448469e+04],\n",
       "       [-7.87673592e-02,  4.76952144e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.69582573e+05],\n",
       "       [ 5.14749900e-03,  4.57526465e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.23960197e+04],\n",
       "       [ 1.90046633e-02,  4.60658135e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.96647180e+04],\n",
       "       [-6.78131844e-02,  4.22861570e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.27734916e+05],\n",
       "       [ 2.85964512e-02,  4.22624158e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.20773658e+04],\n",
       "       [ 4.90739380e-02,  4.79764672e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.41998370e+04],\n",
       "       [-4.87653112e-02,  4.76696843e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  9.30090690e+04],\n",
       "       [-1.00423219e-02,  4.73474417e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.68525599e+04],\n",
       "       [ 1.57447082e-02,  4.28649886e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.17060534e+04],\n",
       "       [ 7.32227336e-02,  5.18210257e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  1.60939716e+05],\n",
       "       [ 3.19131923e-02,  4.31114048e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.75408898e+04],\n",
       "       [ 2.10949606e-03,  4.42382519e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  3.92294502e+04],\n",
       "       [-5.69044231e-03,  4.65686851e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.40204626e+04],\n",
       "       [ 2.59471159e-03,  5.01709571e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  5.04771391e+04],\n",
       "       [-3.02618442e-02,  4.56536909e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  6.00007621e+04],\n",
       "       [ 2.33449481e-02,  4.22340133e-02,  1.00000000e+00,\n",
       "        -1.00000000e+00,  4.65739603e+04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.09454993e-02,  1.90069018e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         8.15123078e+04]),\n",
       " array([ 2.65063051e-02,  1.83262679e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.07687220e+04]),\n",
       " array([ 1.28887417e-02,  1.83086050e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.00264916e+04]),\n",
       " array([ 2.81738044e-02,  1.87914105e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.29376027e+04]),\n",
       " array([-5.94850939e-04,  9.96510492e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.98613669e+05]),\n",
       " array([ 6.39541615e-02,  2.10877240e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         9.06965193e+04]),\n",
       " array([-1.07828803e-01,  1.96106256e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.40232501e+05]),\n",
       " array([ 1.77424122e-02,  2.04079930e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.46255844e+04]),\n",
       " array([ 3.29640386e-03,  4.45299138e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.98755821e+04]),\n",
       " array([-3.30488639e-02,  2.83314122e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.78979188e+04]),\n",
       " array([ 5.40449618e-02,  2.25323090e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         6.85712433e+04]),\n",
       " array([-6.99187737e-02,  2.00176986e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.05786842e+05]),\n",
       " array([-1.09078325e-02,  1.92119797e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         9.76161755e+03]),\n",
       " array([ 1.78834566e-02,  1.86076465e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.33212479e+04]),\n",
       " array([-2.94549574e-02,  1.50751857e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.18971104e+04]),\n",
       " array([-4.41255859e-02,  2.15248349e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         4.82077074e+04]),\n",
       " array([ 3.40636480e-02,  2.72208903e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.80261721e+04]),\n",
       " array([-4.82009820e-02,  1.80481188e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         5.29813746e+04]),\n",
       " array([-1.15444904e-02,  1.75834750e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         8.84907526e+03]),\n",
       " array([-3.30499066e-02,  1.55908756e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.67074292e+04]),\n",
       " array([-4.61133854e-02,  2.18268448e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         5.20570989e+04]),\n",
       " array([-1.79928464e-02,  2.08498525e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.51691744e+04]),\n",
       " array([ 1.25274592e-01,  1.82290295e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.20520354e+05]),\n",
       " array([ 2.12378601e-02,  1.88835961e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.61527348e+04]),\n",
       " array([ 6.08825566e-03,  1.88175658e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         7.82335123e+03]),\n",
       " array([ 7.68314931e-03,  1.89803430e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         8.38568241e+03]),\n",
       " array([ 9.02281968e-02,  2.07569048e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.71439498e+05]),\n",
       " array([-8.00762795e-02,  1.94429429e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.35804744e+05]),\n",
       " array([-3.49155599e-02,  2.01004734e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.24625006e+04]),\n",
       " array([ 2.00366952e-02,  1.82807716e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.47131124e+04]),\n",
       " array([ 4.42300422e-02,  2.03765160e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         4.74299712e+04]),\n",
       " array([-8.49346733e-02,  2.02279636e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.52461354e+05]),\n",
       " array([-2.89714015e-02,  1.97779949e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.46102188e+04]),\n",
       " array([ 5.43207501e-02,  1.96436445e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         6.67323199e+04]),\n",
       " array([ 1.08070929e-02,  2.22632996e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.22489528e+04]),\n",
       " array([ 5.75537090e-02,  5.20612355e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.20456009e+05]),\n",
       " array([ 3.53574876e-02,  2.19277799e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         3.46195823e+04]),\n",
       " array([-3.00303984e-02,  1.82173222e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.46739082e+04]),\n",
       " array([ 9.95392662e-02,  1.92699647e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         2.05587900e+05]),\n",
       " array([-1.69573242e-02,  2.14891122e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         1.49866527e+04]),\n",
       " array([ 5.70047890e-02,  2.21990853e-02,  1.00000000e+00, -1.00000000e+00,\n",
       "         7.48468922e+04])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X, r1), axis=0)\n",
    "y = np.concatenate((y, z2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (155, 5)\n",
      "Labels shape: (155,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.62         9\n",
      "           1       0.83      0.91      0.87        22\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.77      0.73      0.75        31\n",
      "weighted avg       0.80      0.81      0.80        31\n",
      "\n",
      "Trained model saved as 'drone_detector.pkl'\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----- Train a Binary Classifier -----\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ----- Save the Model to a Pickle File -----\n",
    "with open('drone_detector.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "print(\"Trained model saved as 'drone_detector.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading drone segments from ./Data//DroneRF\\AR drone\n",
      "Loading drone segments from ./Data//DroneRF\\Bebop drone\n",
      "Loading drone segments from ./Data//DroneRF\\Phantom drone\n",
      "Loading background segments from ./Data//DroneRF\\Background RF activities\n",
      "Feature matrix shape: (102, 1026)\n",
      "Labels shape: (102,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# ----- Preprocessing Functions -----\n",
    "def moving_average_filter(data, window_size=5):\n",
    "    \"\"\"\n",
    "    Applies a moving average filter (FIR filter with uniform weights)\n",
    "    to smooth the input data.\n",
    "    \"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "def extract_dronerf_features(signal_low, signal_high, fs, n_per_seg, feat_name='SPEC', to_norm=True):\n",
    "    \"\"\"\n",
    "    Compute PSD features for low and high bands using Welch's method,\n",
    "    optionally convert to dB (if feat_name is 'SPEC'), and normalize.\n",
    "    The two PSDs are concatenated to form a single feature vector.\n",
    "    \n",
    "    Parameters:\n",
    "      signal_low: low band signal (1D numpy array)\n",
    "      signal_high: high band signal (1D numpy array)\n",
    "      fs: sampling rate in Hz\n",
    "      n_per_seg: number of samples per segment (for Welch's method)\n",
    "      feat_name: if 'PSD' returns linear PSD; if 'SPEC', converts to dB\n",
    "      to_norm: if True, normalizes the final feature vector\n",
    "      \n",
    "    Returns:\n",
    "      Feature vector (1D numpy array)\n",
    "    \"\"\"\n",
    "    # Compute PSD for low band\n",
    "    freqs_low, psd_low = signal.welch(signal_low, fs, nperseg=n_per_seg)\n",
    "    # Compute PSD for high band\n",
    "    freqs_high, psd_high = signal.welch(signal_high, fs, nperseg=n_per_seg)\n",
    "    \n",
    "    # Concatenate PSD features\n",
    "    feat = np.concatenate((psd_low, psd_high))\n",
    "    \n",
    "    # Convert to dB if feat_name is 'SPEC'\n",
    "    if feat_name == 'SPEC':\n",
    "        feat = -10 * np.log10(feat + 1e-8)  # add epsilon to avoid log(0)\n",
    "    \n",
    "    # Normalize feature vector if required\n",
    "    if to_norm and np.max(feat) != 0:\n",
    "        feat = feat / np.max(feat)\n",
    "    \n",
    "    return feat\n",
    "\n",
    "def load_segment_pair_files(folder_path):\n",
    "    \"\"\"\n",
    "    Groups CSV files in the given folder into segments by pairing the low band (L)\n",
    "    and high band (H) parts.\n",
    "    File naming convention: <segmentID><L/H>_<pairIndex>.csv\n",
    "    Returns a list of tuples: (data_low, data_high).\n",
    "    \"\"\"\n",
    "    segment_dict = {}\n",
    "    pattern = re.compile(r\"(\\d+)([LH])_(\\d+)\\.csv\")\n",
    "    files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    for file in files:\n",
    "        basename = os.path.basename(file)\n",
    "        match = pattern.match(basename)\n",
    "        if match:\n",
    "            seg_id = match.group(1)\n",
    "            band = match.group(2)   # 'L' or 'H'\n",
    "            pair_idx = match.group(3)\n",
    "            key = (seg_id, pair_idx)\n",
    "            if key not in segment_dict:\n",
    "                segment_dict[key] = {}\n",
    "            segment_dict[key][band] = file\n",
    "        else:\n",
    "            print(f\"Filename {basename} did not match expected pattern; skipping.\")\n",
    "    \n",
    "    segments = []\n",
    "    for key, parts in segment_dict.items():\n",
    "        if 'L' in parts and 'H' in parts:\n",
    "            try:\n",
    "                data_low = np.loadtxt(parts['L'], delimiter=',')\n",
    "                data_high = np.loadtxt(parts['H'], delimiter=',')\n",
    "                segments.append((data_low, data_high))\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading segment {key}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping segment {key} because it does not have both low and high band parts.\")\n",
    "    return segments\n",
    "\n",
    "# ----- Define Dataset Paths -----\n",
    "# Replace these with the actual paths to your DroneRF dataset folders.\n",
    "base_dir = './Data//DroneRF'  # e.g., \"/data/DroneRF\"\n",
    "drone_folders = [\n",
    "    os.path.join(base_dir, 'AR drone'),\n",
    "    os.path.join(base_dir, 'Bebop drone'),\n",
    "    os.path.join(base_dir, 'Phantom drone')\n",
    "]\n",
    "background_folder = os.path.join(base_dir, 'Background RF activities')\n",
    "\n",
    "# ----- Parameters for Feature Extraction -----\n",
    "fs = 40e6          # Sampling rate: 40 MHz\n",
    "n_per_seg = 1024   # Number of samples per segment for PSD computation\n",
    "window_size = 5    # Window size for moving average filter\n",
    "feat_name = 'SPEC' # Use 'SPEC' to mimic DroneRFTorch (spectrum in dB)\n",
    "\n",
    "# ----- Load and Process the Data -----\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Process drone segments (label = 1 for drone present)\n",
    "for folder in drone_folders:\n",
    "    print(f\"Loading drone segments from {folder}\")\n",
    "    segment_pairs = load_segment_pair_files(folder)\n",
    "    for (sig_low, sig_high) in segment_pairs:\n",
    "        # Apply moving average filter to each band\n",
    "        filtered_low = moving_average_filter(sig_low, window_size)\n",
    "        filtered_high = moving_average_filter(sig_high, window_size)\n",
    "        # Extract combined feature vector from both bands\n",
    "        features = extract_dronerf_features(filtered_low, filtered_high, fs, n_per_seg, feat_name, to_norm=True)\n",
    "        X.append(features)\n",
    "        y.append(1)\n",
    "\n",
    "# Process background segments (label = 0 for no drone present)\n",
    "print(f\"Loading background segments from {background_folder}\")\n",
    "background_segment_pairs = load_segment_pair_files(background_folder)\n",
    "for (sig_low, sig_high) in background_segment_pairs:\n",
    "    filtered_low = moving_average_filter(sig_low, window_size)\n",
    "    filtered_high = moving_average_filter(sig_high, window_size)\n",
    "    features = extract_dronerf_features(filtered_low, filtered_high, fs, n_per_seg, feat_name, to_norm=True)\n",
    "    X.append(features)\n",
    "    y.append(0)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading background segments from ./Data//DroneRF\\Background RF activities\n"
     ]
    }
   ],
   "source": [
    "r=[]\n",
    "z=[]\n",
    "print(f\"Loading background segments from {background_folder}\")\n",
    "background_segment_pairs = load_segment_pair_files('Data\\DroneRF\\Background RF activites')\n",
    "for (sig_low, sig_high) in background_segment_pairs:\n",
    "    filtered_low = moving_average_filter(sig_low, window_size)\n",
    "    filtered_high = moving_average_filter(sig_high, window_size)\n",
    "    features = extract_dronerf_features(filtered_low, filtered_high, fs, n_per_seg, feat_name, to_norm=True)\n",
    "    r.append(features)\n",
    "    z.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.array(r)\n",
    "z2 = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X, r1), axis=0)\n",
    "y = np.concatenate((y, z2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n",
      "Trained model saved as 'drone_detector.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ----- Train-Test Split -----\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----- Train a Binary Classifier -----\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ----- Save the Model to a Pickle File -----\n",
    "with open('drone_detector-2.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "print(\"Trained model saved as 'drone_detector.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gddrone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
